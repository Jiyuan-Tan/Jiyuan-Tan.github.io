---
layout: cv
permalink: /cv/
title: My CV
tags: [about]
modified: 12-9-2020
comments: false
image:
  feature: yftank.png
---

You can also download my <a href="https://drive.google.com/file/d/18zCacZXH0FSPXjKJHDVWPR8pdO16i9Px/view?usp=sharing" target="_blank">full CV</a>.

## Research Experience
### Zero-Order Optimization
<p align = "right"> 7.2022 – present</p>

_Research Intern, supervised by [Prof. Yinyu Ye](https://web.stanford.edu/~yyye/)_
- Lead a group of three to develop a derivative-free solver1 for nonlinear constrained optimization in ANSI C.
- Use the technique of implicit filtering to increase robustness of algorithm under noises.
- Combine coordinate search to increase efficiency.
- Better performance in solving the Pharmacodynamics problems.

### Stochastic Proximal Point Algorithm with Variance Reduction
<p align = "right"> 1.2022 – 5.2022</p>

_Research Intern, supervised by [Prof. Qi Deng](https://sime.sufe.edu.cn/5b/8d/c10575a154509/page.htm)_
- Propose a stochastic proximal point algorithm algorithm with variance reduction for $\ell_2 $ regularized problems, which contains the SDCA algorithm as a special case.
- Analyze the convergence rate of the proposed algorithm for both convex functions and weakly convex functions.
- Discover that in some situations, proximal algorithms with negative step size have a better convergence rate.

### Reinforcement Learning in Offline Markov Game
<p align = "right"> 1.2021 – 6.2021</p>

_Research Intern, supervised by [Prof. Zhuoran Yang](https://zhaoranwang.github.io/) and  [Prof. Zhaoran Wang](https://www.princeton.edu/~zy6/)_
- Propose the notion of Relative Uncertainty to measure the quality of dataset for offline two-player zero-sum game.
- Analyze the convergence rate of the proposed algorithm PMVI.
- Give a lower bound of the convergence rate by constructing a special game.
- Give a counterexample to illustrate the fundamental difference between Markov Decision Process and Markov Game.
