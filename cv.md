---
layout: cv
permalink: /cv/
title: My CV
tags: [about]
modified: 12-9-2020
comments: false
image:
  feature: yftank.png
---

You can also download my <a href="https://drive.google.com/file/d/18zCacZXH0FSPXjKJHDVWPR8pdO16i9Px/view?usp=sharing" target="_blank">full CV</a>.

## Research Experience
<!-- ### Zero-Order Optimization
<p align = "right"> 7.2022 – present</p>

_Research Intern, supervised by [Prof. Yinyu Ye](https://web.stanford.edu/~yyye/)_
- Lead a group of three to develop a derivative-free solver1 for nonlinear constrained optimization in ANSI C.
- Use the technique of implicit filtering to increase robustness of algorithm under noises.
- Combine coordinate search to increase efficiency. -->

### Zero-Order Optimization
<p align = "right"> 7.2022 -- 7.2023 </p>

_Research Intern, supervised by [Prof. Yinyu Ye](https://web.stanford.edu/~yyye/)_
- Lead a group of three to develop a derivative-free solver for nonlinear constrained optimization in ANSI C. Code available [here](https://github.com/COPT-Public/SOLNP)
- Use the technique of implicit filtering to increase robustness of algorithm under noises.
- Combine coordinate search to increase efficiency. 

### Equilibrium Learning in Offline Markov Game
<p align = "right"> 1.2021 – 6.2021</p>

_Research Intern, supervised by [Prof. Zhuoran Yang](https://zhaoranwang.github.io/) and  [Prof. Zhaoran Wang](https://www.princeton.edu/~zy6/)_
- Propose the notion of Relative Uncertainty to measure the quality of dataset for offline two-player zero-sum game.
- Analyze the convergence rate of the proposed algorithm PMVI.
- Give a lower bound of the convergence rate by constructing a special game.
- Give a counterexample to illustrate the difference between Markov Decision Process and Markov Game.
